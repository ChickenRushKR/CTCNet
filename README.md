## CTCNet


This paper has not yet been published. Once published, the code will be made publicly available.

## Datasets

This method involves using the LRS2, LRS3, and Vox2 datasets to create a multimodal speech separation dataset. The corresponding folders in the provided GitHub repository contain the files necessary to build the datasets, and the code in the [repository](https://github.com/JusperLee/LRS3-For-Speech-Separation) can be used to construct the multimodal datasets.

## Demo



https://user-images.githubusercontent.com/33806018/208616615-dab6ab87-def1-405a-897e-a3c1decb790a.mp4

